{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1e4aefb",
      "metadata": {
        "id": "d1e4aefb"
      },
      "source": [
        "# NYU HPC Guide for Beyond the Hype: LLMs vs. Traditional ML in the Real World"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de21c2e5",
      "metadata": {
        "id": "de21c2e5"
      },
      "source": [
        "## Table of Contents\n",
        "1. Logging In\n",
        "2. Understanding the Filesystem\n",
        "3. Setting up the Environment\n",
        "   - Installing Conda\n",
        "4. Request Compute Node\n",
        "   - Interactive Jobs\n",
        "     - With GPU\n",
        "     - Without GPU\n",
        "   - Batch Jobs\n",
        "     - With GPU\n",
        "     - Without GPU\n",
        "5. Using OOD and Jupyter Notebook\n",
        "   - With GPU\n",
        "   - Without GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b29d3c0",
      "metadata": {
        "id": "4b29d3c0"
      },
      "source": [
        "## Logging In\n",
        "\n",
        "To access the Greene HPC cluster, you need to be on the NYU network. If you're off-campus, connect via the [NYU VPN](https://www.nyu.edu/life/information-technology/infrastructure/network-services/vpn.html).\n",
        "\n",
        "### Steps to Log In\n",
        "\n",
        "1. **Open a Terminal** on your local machine.\n",
        "\n",
        "2. **Connect via SSH** (replace `[netid]` with your NYU NetID):\n",
        "   ```bash\n",
        "   ssh [netid]@greene.hpc.nyu.edu\n",
        "   ```\n",
        "\n",
        "3. You will see a welcome message upon successful login."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3246c3e",
      "metadata": {
        "id": "b3246c3e"
      },
      "source": [
        "## Understanding the Filesystem\n",
        "\n",
        "All the datasets and environment files for the workshop are located under `/vast/rs8020-share/`.\n",
        "\n",
        "The Greene HPC cluster has different directories optimized for various storage needs:\n",
        "\n",
        "| Directory  | Variable   | Purpose                | Flushed After | Quota             |\n",
        "|------------|------------|------------------------|---------------|-------------------|\n",
        "| `/archive` | `$ARCHIVE` | Long-term storage      | No            | 2TB / 20K inodes  |\n",
        "| `/home`    | `$HOME`    | Configuration files    | No            | 50GB / 30K inodes |\n",
        "| `/scratch` | `$SCRATCH` | Temporary data storage | Yes (60 days) | 5TB / 1M inodes   |\n",
        "\n",
        "Check your quota:\n",
        "```bash\n",
        "myquota\n",
        "```\n",
        "\n",
        "**Recommended:** Store your data in `/scratch/[netid]` for the workshop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b3b990",
      "metadata": {
        "id": "23b3b990"
      },
      "source": [
        "## Setting up the Environment\n",
        "\n",
        "### Installing Conda Inside the Singularity Container\n",
        "\n",
        "1. **Create a directory in scratch:**\n",
        "   ```bash\n",
        "   mkdir /scratch/<NetID>/hackathon\n",
        "   cd /scratch/<NetID>/hackathon\n",
        "   ```\n",
        "\n",
        "2. **Copy overlay and environment files:**\n",
        "   ```bash\n",
        "   cp -rp /vast/rs8020-share/overlay-25GB-500K.ext3 .\n",
        "   cp -rp /vast/rs8020-share/environment.yml .\n",
        "   ```\n",
        "\n",
        "3. **Copy Singularity image:**\n",
        "   ```bash\n",
        "   cp -rp /scratch/work/public/singularity/cuda11.8.86-cudnn8.7-devel-ubuntu22.04.2.sif .\n",
        "   ```\n",
        "\n",
        "4. **Start Singularity:**\n",
        "   ```bash\n",
        "   singularity exec --bind /scratch --nv --overlay /scratch/<NetID>/hackathon/overlay-25GB-500K.ext3:rw \\\n",
        "   /scratch/<NetID>/hackathon/cuda11.8.86-cudnn8.7-devel-ubuntu22.04.2.sif /bin/bash\n",
        "   ```\n",
        "\n",
        "5. **Install Conda inside Singularity:**\n",
        "\n",
        "   Inside the Singularity container:\n",
        "\n",
        "   ```bash\n",
        "   cd /ext3/\n",
        "   wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "   bash ./Miniconda3-latest-Linux-x86_64.sh -b -p /ext3/miniconda3\n",
        "   rm Miniconda3-latest-Linux-x86_64.sh  # Remove installer\n",
        "   ```\n",
        "\n",
        "6. **Initialize Conda:**\n",
        "\n",
        "   ```bash\n",
        "   source /ext3/miniconda3/etc/profile.d/conda.sh\n",
        "   export PATH=/ext3/miniconda3/bin:$PATH\n",
        "   ```\n",
        "\n",
        "7. **Create the Conda environment from the YAML file:**\n",
        "\n",
        "   ```bash\n",
        "   conda env create -f /scratch/<NetID>/hackathon/environment.yml\n",
        "   conda activate hackathon\n",
        "   ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8d8bfbb",
      "metadata": {
        "id": "c8d8bfbb"
      },
      "source": [
        "## Request Compute Node\n",
        "\n",
        "**IMPORTANT: Do not run computations on the login node. Always request a compute node.**\n",
        "\n",
        "### Interactive Jobs (for Development)\n",
        "\n",
        "#### With GPU\n",
        "\n",
        "1. **Request an interactive session with GPU:**\n",
        "\n",
        "   ```bash\n",
        "   srun --reservation=cds-hackathon --gres=gpu:rtx8000:1 --time=04:00:00 --mem=64G --pty /bin/bash\n",
        "   ```\n",
        "\n",
        "2. **Once on compute node, start Singularity:**\n",
        "\n",
        "   ```bash\n",
        "   singularity exec --overlay /scratch/<NetID>/hackathon/overlay-25GB-500K.ext3:rw \\\n",
        "       --bind /scratch \\\n",
        "       --nv \\\n",
        "       /scratch/<NetID>/hackathon/cuda11.8.86-cudnn8.7-devel-ubuntu22.04.2.sif \\\n",
        "       /bin/bash\n",
        "   ```\n",
        "\n",
        "3. **Set up environment:**\n",
        "\n",
        "   ```bash\n",
        "   source /ext3/miniconda3/etc/profile.d/conda.sh\n",
        "   conda activate hackathon\n",
        "   ```\n",
        "\n",
        "4. **Run your code:**\n",
        "\n",
        "   ```bash\n",
        "   python your_script.py\n",
        "   ```\n",
        "\n",
        "#### Without GPU\n",
        "\n",
        "1. **Request an interactive session without GPU:**\n",
        "\n",
        "   ```bash\n",
        "   srun --reservation=cds-hackathon --time=04:00:00 --mem=64G --pty /bin/bash\n",
        "   ```\n",
        "\n",
        "2. **Once on compute node, start Singularity (without `--nv` flag):**\n",
        "\n",
        "   ```bash\n",
        "   singularity exec --overlay /scratch/<NetID>/hackathon/overlay-25GB-500K.ext3:rw \\\n",
        "       --bind /scratch \\\n",
        "       /scratch/<NetID>/hackathon/cuda11.8.86-cudnn8.7-devel-ubuntu22.04.2.sif \\\n",
        "       /bin/bash\n",
        "   ```\n",
        "\n",
        "3. **Set up environment:**\n",
        "\n",
        "   ```bash\n",
        "   source /ext3/miniconda3/etc/profile.d/conda.sh\n",
        "   conda activate hackathon\n",
        "   ```\n",
        "\n",
        "4. **Run your code:**\n",
        "\n",
        "   ```bash\n",
        "   python your_script.py\n",
        "   ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac9e5e31",
      "metadata": {
        "id": "ac9e5e31"
      },
      "source": [
        "### Batch Jobs (for Training)\n",
        "\n",
        "#### With GPU\n",
        "\n",
        "1. **Create a job script (save as `job_gpu.slurm`):**\n",
        "\n",
        "   ```bash\n",
        "   #!/bin/bash\n",
        "   #SBATCH --job-name=hackathon_gpu\n",
        "   #SBATCH --output=slurm_%j.out\n",
        "   #SBATCH --error=slurm_%j.err\n",
        "   #SBATCH --export=ALL\n",
        "   #SBATCH --time=04:00:00\n",
        "   #SBATCH --mem=64G\n",
        "   #SBATCH --reservation=cds-hackathon\n",
        "   #SBATCH --gres=gpu:rtx8000:1\n",
        "\n",
        "   singularity exec --overlay /scratch/<NetID>/hackathon/overlay-25GB-500K.ext3:rw \\\n",
        "       --bind /scratch \\\n",
        "       --nv \\\n",
        "       /scratch/<NetID>/hackathon/cuda11.8.86-cudnn8.7-devel-ubuntu22.04.2.sif \\\n",
        "       /bin/bash -c \"\n",
        "   source /ext3/miniconda3/etc/profile.d/conda.sh\n",
        "   conda activate hackathon\n",
        "   python your_script.py\n",
        "   \"\n",
        "   ```\n",
        "\n",
        "2. **Submit the job:**\n",
        "\n",
        "   ```bash\n",
        "   sbatch job_gpu.slurm\n",
        "   ```\n",
        "\n",
        "#### Without GPU\n",
        "\n",
        "1. **Create a job script (save as `job_nogpu.slurm`):**\n",
        "\n",
        "   ```bash\n",
        "   #!/bin/bash\n",
        "   #SBATCH --job-name=hackathon_nogpu\n",
        "   #SBATCH --output=slurm_%j.out\n",
        "   #SBATCH --error=slurm_%j.err\n",
        "   #SBATCH --export=ALL\n",
        "   #SBATCH --time=04:00:00\n",
        "   #SBATCH --mem=64G\n",
        "   #SBATCH --reservation=cds-hackathon\n",
        "\n",
        "   singularity exec --overlay /scratch/<NetID>/hackathon/overlay-25GB-500K.ext3:rw \\\n",
        "       --bind /scratch \\\n",
        "       /scratch/<NetID>/hackathon/cuda11.8.86-cudnn8.7-devel-ubuntu22.04.2.sif \\\n",
        "       /bin/bash -c \"\n",
        "   source /ext3/miniconda3/etc/profile.d/conda.sh\n",
        "   conda activate hackathon\n",
        "   python your_script.py\n",
        "   \"\n",
        "   ```\n",
        "\n",
        "2. **Submit the job:**\n",
        "\n",
        "   ```bash\n",
        "   sbatch job_nogpu.slurm\n",
        "   ```\n",
        "\n",
        "3. **Monitor your job:**\n",
        "\n",
        "   ```bash\n",
        "   squeue -u $USER  # Check job status\n",
        "   scancel <job_id>  # Cancel job if needed\n",
        "   ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24df7e6e",
      "metadata": {
        "id": "24df7e6e"
      },
      "source": [
        "## Using OOD and Jupyter Notebook\n",
        "\n",
        "### Access OOD\n",
        "\n",
        "1. **Log in to Greene cluster at least once using terminal.**\n",
        "\n",
        "2. **Connect to NYU VPN.**\n",
        "\n",
        "3. **Access OOD at [https://ood.hpc.nyu.edu](https://ood.hpc.nyu.edu).**\n",
        "\n",
        "### Set Up Custom Kernel\n",
        "\n",
        "1. **In Singularity container, install `ipykernel`:**\n",
        "\n",
        "   ```bash\n",
        "   conda install ipykernel\n",
        "   ```\n",
        "\n",
        "2. **Create a custom kernel:**\n",
        "\n",
        "   ```bash\n",
        "   python -m ipykernel install --user --name=hackathon\n",
        "   ```\n",
        "\n",
        "3. **Copy kernel template:**\n",
        "\n",
        "   ```bash\n",
        "   mkdir -p ~/.local/share/jupyter/kernels/hackathon\n",
        "   cd ~/.local/share/jupyter/kernels/hackathon\n",
        "   cp -R /share/apps/mypy/src/kernel_template/* .\n",
        "   ```\n",
        "\n",
        "4. **Update the `python` file in the kernel directory:**\n",
        "\n",
        "   Replace the content with:\n",
        "\n",
        "   ```bash\n",
        "   #!/bin/bash\n",
        "\n",
        "   nv=\"\"\n",
        "   if [[ $(command -v nvidia-smi) ]]; then\n",
        "       nv=\"--nv\"\n",
        "   fi\n",
        "\n",
        "   singularity exec $nv \\\n",
        "       --overlay /scratch/<NetID>/hackathon/overlay-25GB-500K.ext3:rw \\\n",
        "       /scratch/<NetID>/hackathon/cuda11.8.86-cudnn8.7-devel-ubuntu22.04.2.sif \\\n",
        "       /bin/bash -c \"source /ext3/miniconda3/etc/profile.d/conda.sh; conda activate hackathon; python \\\"\\$@\\\"\"\n",
        "   ```\n",
        "\n",
        "   Make sure to replace `<NetID>` with your actual NetID.\n",
        "\n",
        "5. **Update `kernel.json`:**\n",
        "\n",
        "   ```json\n",
        "   {\n",
        "     \"argv\": [\n",
        "       \"/home/<NetID>/.local/share/jupyter/kernels/hackathon/python\",\n",
        "       \"-m\",\n",
        "       \"ipykernel_launcher\",\n",
        "       \"-f\",\n",
        "       \"{connection_file}\"\n",
        "     ],\n",
        "     \"display_name\": \"hackathon\",\n",
        "     \"language\": \"python\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "6. **Launch Jupyter through OOD:**\n",
        "\n",
        "   - Go to **Interactive Apps > Jupyter Notebook**.\n",
        "   - Configure with these settings:\n",
        "\n",
        "     - **Partition:** `nvidia` (or `cpu` for no GPU)\n",
        "     - **Number of hours:** `4`\n",
        "     - **Memory:** `64GB`\n",
        "     - **Number of GPUs:** `1` (set to `0` for no GPU)\n",
        "     - **GPU Type:** `RTX8000`\n",
        "     - **Additional Slurm Parameters:**\n",
        "\n",
        "       ```bash\n",
        "       --reservation=cds-hackathon\n",
        "       ```\n",
        "\n",
        "   - **Launch** and wait for the job to start.\n",
        "\n",
        "7. **Select your custom kernel** when the Jupyter Notebook interface loads.\n",
        "\n",
        "#### Without GPU\n",
        "\n",
        "When configuring the Jupyter Notebook in OOD without GPU:\n",
        "\n",
        "- **Partition:** `cpu`\n",
        "- **Number of GPUs:** `0`\n",
        "- Remove `--gres` options from Additional Slurm Parameters if present."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}